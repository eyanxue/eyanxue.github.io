<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  2.5 Pro
  experiment

  Our most powerful thinking model with maximum response accuracy and state-of-the-art performance

  2.5 Flash
  experiment

  Our best model in terms of price-performance, offering well-rounded
  capabilities.

  2.0 Flash
  spark

  Our newest multimodal model, with next generation features and improved
  capabilities
The Gemini API offers different models that are optimized for specific use cases. Here's a brief overview of Gemini variants that are available:You can view the rate limits for each model on the rate limits page.
Our best model in terms of price-performance, offering well-rounded
capabilities.

Gemini 2.5 Flash rate limits are more restricted since it is an experimental / preview
model.   Try in Google AI StudioInputsText, images, video, audioOutputTextInput token limit1,048,576Output token limit65,536Audio generationNot supportedCachingSupportedCode executionSupportedFunction callingSupportedImage generationNot supportedSearch groundingSupportedStructured outputsSupportedThinkingSupportedTuningNot supported
Our native audio dialog models, with and without thinking, available through
the Live API. These models provide
interactive and unstructured conversational experiences, with style and
control prompting.   Try native audio in Google AI StudioInputsAudio, video, textOutputAudio and textInput token limit128,000Output token limit8,000Audio generationSupportedCachingNot supportedCode executionNot supportedFunction callingSupportedImage generationNot supportedSearch groundingSupportedStructured outputsNot supportedThinkingSupportedTuningNot supported
Gemini 2.5 Flash Preview TTS is our price-performant text-to-speech model,
delivering high control and transparency for structured workflows like
podcast generation, audiobooks, customer support, and more.
Gemini 2.5 Flash rate limits are more restricted since it is an experimental
/ preview model.   Try in Google AI StudioInputsTextOutputAudioInput token limit8,000Output token limit16,000Structured outputsNot supportedCachingNot supportedTuningNot supportedFunction callingNot supportedCode executionNot supportedSearchNot supportedAudio generationSupportedLive APINot supportedThinkingNot supported
Gemini 2.5 Pro is our state-of-the-art thinking model,
capable of reasoning over complex problems in code, math, and STEM, as well
as analyzing large datasets, codebases, and documents using long context.

Gemini 2.5 Pro rate limits are more restricted since it is a preview
model.   Try in Google AI StudioInputsAudio, images, video, and textOutputTextInput token limit1,048,576Output token limit65,536Structured outputsSupportedCachingSupportedTuningNot supportedFunction callingSupportedCode executionSupportedSearch groundingSupportedImage generationNot supportedAudio generationNot supportedLive APINot supportedThinkingSupported
Gemini 2.5 Pro Preview TTS is our most powerful text-to-speech model,
delivering high control and transparency for structured workflows like
podcast generation, audiobooks, customer support, and more.
Gemini 2.5 Pro rate limits are more restricted since it is an experimental
/ preview model.   Try in Google AI StudioInputsTextOutputAudioInput token limit8,000Output token limit16,000Structured outputsNot supportedCachingNot supportedTuningNot supportedFunction callingNot supportedCode executionNot supportedSearchNot supportedAudio generationSupportedLive APINot supportedThinkingNot supported
Gemini 2.0 Flash delivers next-gen features and improved capabilities,
including superior speed, native tool use, and a 1M token
context window.   Try in Google AI StudioInputsAudio, images, video, and textOutputTextInput token limit1,048,576Output token limit8,192Structured outputsSupportedCachingSupportedTuningNot supportedFunction callingSupportedCode executionSupportedSearchSupportedImage generationNot supportedAudio generationNot supportedLive APISupportedThinkingExperimental
Gemini 2.0 Flash Preview Image Generation delivers improved image generation features, including generating and editing images conversationally.   Try in Google AI StudioInputsAudio, images, video, and textOutputText and imagesInput token limit32,000Output token limit8,192Structured outputsSupportedCachingSupportedTuningNot supportedFunction callingNot supportedCode executionNot SupportedSearchNot SupportedImage generationSupportedAudio generationNot supportedLive APINot SupportedThinkingNot Supportedgemini-2.0-flash-preview-image-generation is not currently supported in a number of countries in Europe, Middle East &amp; AfricaA Gemini 2.0 Flash model optimized for cost efficiency and low latency.Try in Google AI StudioInputsAudio, images, video, and textOutputTextInput token limit1,048,576Output token limit8,192Structured outputsSupportedCachingSupportedTuningNot supportedFunction callingSupportedCode executionNot supportedSearchNot supportedImage generationNot supportedAudio generationNot supportedLive APINot supported
Gemini 1.5 Flash is a fast and versatile multimodal model for scaling across
diverse tasks.   Try in Google AI StudioInputsAudio, images, video, and textOutputTextInput token limit1,048,576Output token limit8,192Maximum number of images per prompt3,600Maximum video length1 hourMaximum audio lengthApproximately 9.5 hoursSystem instructionsSupportedJSON modeSupportedJSON schemaSupportedAdjustable safety settingsSupportedCachingSupportedTuningSupportedFunction callingSupportedCode executionSupportedLive APINot supported
Gemini 1.5 Flash-8B is a small model designed for lower intelligence tasks.   Try in Google AI StudioInputsAudio, images, video, and textOutputTextInput token limit1,048,576Output token limit8,192Maximum number of images per prompt3,600Maximum video length1 hourMaximum audio lengthApproximately 9.5 hoursSystem instructionsSupportedJSON modeSupportedJSON schemaSupportedAdjustable safety settingsSupportedCachingSupportedTuningSupportedFunction callingSupportedCode executionSupportedLive APINot supported
Try Gemini 2.5 Pro Preview, our most advanced Gemini model to date.
  
Gemini 1.5 Pro is a mid-size multimodal model that is optimized for
a wide-range of reasoning tasks. 1.5 Pro can process large amounts of data
at once, including 2 hours of video, 19 hours of audio, codebases with
60,000 lines of code, or 2,000 pages of text.   Try in Google AI StudioInputsAudio, images, video, and textOutputTextInput token limit2,097,152Output token limit8,192Maximum number of images per prompt7,200Maximum video length2 hoursMaximum audio lengthApproximately 19 hoursSystem instructionsSupportedJSON modeSupportedJSON schemaSupportedAdjustable safety settingsSupportedCachingSupportedTuningNot supportedFunction callingSupportedCode executionSupportedLive APINot supported
Imagen 3 is our highest quality text-to-image model, capable of generating
images with even better detail, richer lighting and fewer distracting artifacts
than our previous models.   Gemini APIimagen-3.0-generate-002InputTextOutputImagesInput token limitN/AOutput imagesUp to to 4
Veo 2 is our high quality text- and image-to-video model, capable of generating
detailed videos, capturing the artistic nuance in your prompts.   Gemini APIveo-2.0-generate-001InputText, imageOutputVideoText inputN/AImage inputAny image resolution and aspect ratio up to 20MB file sizeOutput videoUp to 2
The Gemini 2.0 Flash Live model works with the Live API to enable low-latency
bidirectional voice and video interactions
with Gemini. The model can process text, audio, and video input, and it can
provide text and audio output.   Try in Google AI StudioInputsAudio, video, and textOutputText, and audioInput token limit1,048,576Output token limit8,192Structured outputsSupportedTuningNot supportedFunction callingSupportedCode executionSupportedSearchSupportedImage generationNot supportedAudio generationSupportedThinkingNot supported
Gemini embedding achieves a SOTA performance
across many key dimensions including code, multi-lingual, and retrieval.

Gemini Embedding rate limits are more restricted since it is an experimental
model.   Gemini APIgemini-embedding-exp-03-07InputTextOutputText embeddingsInput token limit8,192Output dimension sizeElastic, supports: 3072, 1536, or 768
Try our new experimental Gemini embedding model
which achieves state-of-the-art performance.
  
Text embeddings are used to measure the relatedness of strings and are widely used in
many AI applications.
  
text-embedding-004 achieves a stronger retrieval performance and outperforms existing models
with comparable dimensions, on the standard MTEB embedding benchmarks.   Gemini APImodels/text-embedding-004InputTextOutputText embeddingsInput token limit2,048Output dimension size768
You can use the Embedding model to generate
text embeddings for
input text.
The Embedding model is optimized for creating embeddings with 768 dimensions
for text of up to 2,048 tokens.   InputTextOutputText embeddingsInput token limit2,048Output dimension size768
You can use the AQA model to perform
Attributed Question-Answering
(AQA)â€“related tasks over a document, corpus, or a set of passages. The AQA
model returns answers to questions that are grounded in provided sources,
along with estimating answerable probability.   InputTextOutputTextInput token limit7,168Output token limit1,024See the examples to explore the capabilities of these model variations.   [*]  A token is equivalent to about 4 characters for Gemini models. 100 tokens   are about 60-80 English words. Gemini models are available in either stable, preview, or experimental versions. In your code, you can use one of the following model name formats to specify which model and version you want to use.Points to the most recent stable version released for the specified model generation and variation.To specify the latest stable version, use the following pattern:
</code></pre></div></div>
<model>-<generation>-<variation>. For example, gemini-2.0-flash.Points to a specific stable model. Stable models usually don't change. Most
production apps should use a specific stable model.To specify a stable version, use the following pattern:
<model>-<generation>-<variation>-<version>. For example,
gemini-2.0-flash-001.Points to a preview model which may not be suitable for production use, come
with more restrictive rate limits, but may have billing enabled.To specify a preview version, use the following pattern:
<model>-<generation>-<variation>-<version>. For example,
gemini-2.5-pro-preview-06-05.Points to an experimental model which may not be suitable for production use and
come with more restrictive rate limits. We release experimental models to gather
feedback and get our latest updates into the hands of developers quickly.To specify an experimental version, use the following pattern:
<model>-<generation>-<variation>-<version>. For example,
gemini-2.0-pro-exp-02-05.In addition to stable models, the Gemini API offers experimental models which may
not be suitable for production use and come with more restrictive rate limits.We release experimental models to gather feedback, get our
latest updates into the hands of developers quickly, and highlight the pace of
innovation happening at Google. What we learn from experimental launches informs
how we release models more widely. An experimental model can be swapped for
another without prior notice. We don't guarantee that an experimental model will
become a stable model in the future.As new versions or stable releases become available, we remove and replace
experimental models. You can find the previous experimental models we released
in the following section along with the replacement version:Gemini models are trained to work with the following languages:Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.Last updated 2025-06-09 UTC.
</version></variation></generation></model></version></variation></generation></model></version></variation></generation></model></variation></generation></model>
</body></html>
